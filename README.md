## Data-Engineering-with-Databricks 
My Personel DA handbook/Practice Material

I practised the core Databricks funtionalities 
## Transformation of Data With Spark, Managed Data with Delta Lake, Built Data Pipelines with Delta Live Tables, Managed Data Access with Unity Catalog.

## Notebook 1: Data Extraction
Worked with a sample of raw Kafka data written as JSON files. 
## My Learning Outcomes
- Used Spark SQL to directly query data files.
- Create tables against external data sources for various file formats.
- Describe default behavior when querying tables defined against external sources.
- Applied Layer views and CTEs to make referencing data files easier.
- Leveraged **`text`** and **`binaryFile`** methods to review raw file contents.

## Contents
 - Query a Single File.
 - Query a Directory of Files.
 - Create References to Files.
 - Create Temporary References to Files.
 - CTEs for Reference within a Query.
 - Extract Text Files as Raw Strings.
 - Extract the Raw Bytes and Metadata of a File.
 - Registering Tables on External Data with Read Options.
 - Limits of Tables with External Data Sources.
 - Extracting Data from SQL Databases.
